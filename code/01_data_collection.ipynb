{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d2e60db",
   "metadata": {},
   "source": [
    "# Reddit NLP Classifier\n",
    "\n",
    "## Data Collection (1/4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424bf2ea",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Data Collection](#Data-Collection)\n",
    "- [Data Dictionary](#Data-Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09398430",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fa13ed",
   "metadata": {},
   "source": [
    "For this project, `r/malefashionadvice` & `r/femalefashionadvice` subreddits were selected. Their posts were collected using the `Pushshift's API` and the `requests` library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e2edb",
   "metadata": {},
   "source": [
    "### All libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b6b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11955b5f",
   "metadata": {},
   "source": [
    "### Create a reusable function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92949a76",
   "metadata": {},
   "source": [
    "A reusable function was created retrieve posts from each subreddit. The function also raises an error when HTTP status response is not 200. Additionally, it removes comments by AutoModerator. Since Pushshift limits requests to 500 posts, a loop was used in the function to obtain more than 500 posts from each subreddit. This project required to use at least 1,000 posts from each subreddit. Also, `time.sleep()` function was included to provide the server with a short break between queries. Lastly, the posts date range was set to include posts from March 1 or older, to ensure that the same posts would be retrieved each time the code was run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3fb51bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://youtu.be/AcrjEWsMi_E\n",
    "# Reference: https://github.com/pushshift/api.git\n",
    "# Reference: https://www.epochconverter.com/\n",
    "# Reference: GA 503 API Solution Code Lesson \n",
    "# Reference: https://stackoverflow.com/questions/40045545/pandas-query-string-where-column-name-contains-special-characters\n",
    "\n",
    "def subreddit_comment(subreddit, num_post):\n",
    "    # Target web page \n",
    "    url = 'https://api.pushshift.io/reddit/search/comment'   \n",
    "    # Set the parameters \n",
    "    params = {\n",
    "        'subreddit': subreddit,\n",
    "        'size': 500,\n",
    "        'before': 1677718897 # Set to March 1, 2023\n",
    "    }\n",
    "    \n",
    "    # Establish the connection to the web page\n",
    "    res = requests.get(url, params)\n",
    "    # Raise an error if HTTP status response is not 200 \n",
    "    if res.status_code != 200:\n",
    "        return f\"Error {res.status_code}: \\\n",
    "        Unable to retrieve data from {subreddit}. Please try again.\"\n",
    "    else:\n",
    "        # Store data in json form \n",
    "        data = res.json()\n",
    "        # Store data in data column \n",
    "        posts = data['data']\n",
    "        # Save it in dataframe \n",
    "        data_df = pd.DataFrame(posts)\n",
    "        # Remove comments by AutoModerator\n",
    "        df1 = data_df.query('author != \"AutoModerator\"')\n",
    "\n",
    "    # Loop above process if data size is smaller than `num_post`\n",
    "    while len(df1) < num_post:\n",
    "        # Get older posts from previous extraction\n",
    "        prev_post = df1[['created_utc']].iloc[-1]\n",
    "        # Set the parameters\n",
    "        params = {\n",
    "            'subreddit': subreddit,\n",
    "            'size': 500,\n",
    "            'before': prev_post\n",
    "        }\n",
    "        \n",
    "        # Establish the connection to the web page\n",
    "        res = requests.get(url, params)\n",
    "        # Raise an error if HTTP status response is not 200 \n",
    "        if res.status_code != 200:\n",
    "            return f\"Error {res.status_code}: \\\n",
    "            Unable to retrieve data from {subreddit}. Please try again.\"\n",
    "        else:\n",
    "            # Store data in json form \n",
    "            data = res.json()\n",
    "            # Store data in data column \n",
    "            posts = data['data']\n",
    "            # Save it in dataframe \n",
    "            data_df = pd.DataFrame(posts)\n",
    "            # Remove comments by AutoModerator and [removed] comments\n",
    "            df2 = data_df.query('author != \"AutoModerator\"')\n",
    "            \n",
    "            # Concatenate datasets \n",
    "            df_concat = pd.concat([df1, df2])\n",
    "            df1 = df_concat.drop_duplicates(subset='body')\n",
    "        # Provide the server with a short break between queries\n",
    "        time.sleep(5) \n",
    "    return df_concat.drop_duplicates(subset='body').reset_index()[['subreddit', \n",
    "                                                                   'body', \n",
    "                                                                   'created_utc']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab43040",
   "metadata": {},
   "source": [
    "### Collected data using the above function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f34ee",
   "metadata": {},
   "source": [
    "The comments from two subreddits: `r/malefashionadvice` and `r/femalefashionadvice` were collected, using the above function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f7dc88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2778, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a function to retreive comments from two subreddits \n",
    "malefashion=subreddit_comment('malefashionadvice', 2500)\n",
    "# Check the datashape\n",
    "malefashion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07e71f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2793, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a function to retreive comments from two subreddits \n",
    "femalefashion=subreddit_comment('femalefashionadvice', 2500)\n",
    "# Check the datashape\n",
    "femalefashion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fddfb9",
   "metadata": {},
   "source": [
    "### Check post creation date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a42d33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>malefashionadvice</td>\n",
       "      <td>Definitely agree there’s personality there. Se...</td>\n",
       "      <td>1677718806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>malefashionadvice</td>\n",
       "      <td>Walmart brand now.  Saw them today</td>\n",
       "      <td>1677456121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit                                               body  \\\n",
       "0     malefashionadvice  Definitely agree there’s personality there. Se...   \n",
       "2777  malefashionadvice                 Walmart brand now.  Saw them today   \n",
       "\n",
       "      created_utc  \n",
       "0      1677718806  \n",
       "2777   1677456121  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the post date range \n",
    "pd.concat([malefashion.iloc[[0]], malefashion.iloc[[-1]]])\n",
    "\n",
    "# 1677718806 - Thursday, March 1, 2023 (CT)\n",
    "# 1677588766 - Tuesday, February 28, 2023 (CT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23af43d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>femalefashionadvice</td>\n",
       "      <td>30th is auto-permission to go wild. Btw, 40 wa...</td>\n",
       "      <td>1677718502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>femalefashionadvice</td>\n",
       "      <td>Any ideas on linen pants that aren't see throu...</td>\n",
       "      <td>1677390987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                subreddit                                               body  \\\n",
       "0     femalefashionadvice  30th is auto-permission to go wild. Btw, 40 wa...   \n",
       "2792  femalefashionadvice  Any ideas on linen pants that aren't see throu...   \n",
       "\n",
       "      created_utc  \n",
       "0      1677718502  \n",
       "2792   1677390987  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the post date range \n",
    "pd.concat([femalefashion.iloc[[0]], femalefashion.iloc[[-1]]])\n",
    "\n",
    "# 1677718502 - Wednesday, March 1, 2023 (CT)\n",
    "# 1677601359 - Tuesday, February 28, 2023 (CT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc1014",
   "metadata": {},
   "source": [
    "After checking post creation date, deleted this column for the clean dataset as it is irrelevant for the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79597857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete created_utc from both subreddits \n",
    "malefashion.drop(columns = 'created_utc', inplace=True)\n",
    "femalefashion.drop(columns = 'created_utc', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf27fa4",
   "metadata": {},
   "source": [
    "### Combine two subreddits data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc1ef4",
   "metadata": {},
   "source": [
    "The posts from both subreddits were then combined into a single dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2c25858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two subreddits together\n",
    "df = pd.concat([malefashion, femalefashion], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "192003e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5571 entries, 0 to 5570\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  5571 non-null   object\n",
      " 1   body       5571 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c560e",
   "metadata": {},
   "source": [
    "### Save dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b61a7d",
   "metadata": {},
   "source": [
    "The combined subreddits dataset was saved in csv format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9938d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe \n",
    "df.to_csv('../data/subreddits_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc1669",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7163a98",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Discription|\n",
    "|----|----|----|----|\n",
    "|subreddit|object|Reddit's two subreddits (r/malefashionadvice & r/femalefashionadvice)|Subreddit (Reddit's community) name|\n",
    "|body|object|Reddit's two subreddits (r/malefashionadvice & r/femalefashionadvice)|Actual text from the post|\n",
    "|created_utc|int64|Reddit's two subreddits (r/malefashionadvice & r/femalefashionadvice)|Date of submission creation(epoch time)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34851ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
